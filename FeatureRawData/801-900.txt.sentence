"LATE O
PENALTY O
APPLIED O
(days): O
0OUTPUT O
MARK O
(out O
of O
15): O
8.88 O
------------------- O
COMMENTS O
--------------------OUTPUT O
PERFORMANCE: O
F1 O
score O
of O
ac:0.9072088332094702 O
F1 O
score O
of O
ev:0.13114754098360654 O
F1 O
score O
of O
oven:0.5061124694376529 O
F1 O
score O
of O
wash:0.11120749965020288 O
F1 O
score O
of O
dryer:0.11984230336978431 O
Average O
F1 O
score O
of O
all:0.3551037293301434 O
MODEL DESCRIPTION AND DEVELOPMENT: The model development and description task is performed fairly but there are rooms to improve. It is better to give more depth when comparing models’ pros and cons and justify why you chose these modeling techniques to solve the problem in hand.	Sensemaking 1&Impact 1
Moreover, more explanation is expected regarding the model development phase especially in feature selection and hyperparameters tuning.	Sensemaking 1
It is important to assure the readers that you are developing and comparing the models in a fair and robust setting.	Sensemaking 1
MODEL EVALUATION AND INFERENCE: Model evaluation is fine.	Sensemaking 1
More effort is needed for model inference.	Sensemaking 1
CODE AND REPORT READIBILITY: The report is well structured.	Sensemaking 1
The ideas are properly explained.	Sensemaking 1
However, the formatting is not consistent among the theme.	Sensemaking 1
There are some confusing subsection titles, such as &amp;quot;dummy variable&amp;quot;, which cannot clearly describe what the section is about.	Sensemaking 1
The program is well documented with no redundant codes.	Sensemaking 1
The README file is missing most of the necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc.}""	Sensemaking 1
data-sheets-userformat=""{2:14594,4:[null,2,16777215],11:3,14:[null,2,0],15:Inconsolata, O
monospace, O
arial, O
sans, O
sans-serif,16:11}"" O
data-sheets-formula=""=SUBSTITUTE(SUBSTITUTE(R[0]C[-1], O
char(10), O
&amp; O
char(10) O
),,&amp;quot;)"">FINAL O
MARK O
(out O
of O
35): O
21.13&lt;br O
\&gt;LATE O
PENALTY O
APPLIED O
(days): O
0&lt;br O
\&gt;OUTPUT O
MARK O
(out O
of O
15): O
8.88&lt;br O
\&gt; O
------------------- O
COMMENTS O
--------------------&lt;br O
\&gt;OUTPUT O
PERFORMANCE: O
&lt;br O
\&gt;F1 O
score O
of O
ac:0.9072088332094702 O
&lt;br O
\&gt; O
F1 O
score O
of O
ev:0.13114754098360654 O
&lt;br O
\&gt; O
F1 O
score O
of O
oven:0.5061124694376529 O
&lt;br O
\&gt; O
F1 O
score O
of O
wash:0.11120749965020288 O
&lt;br O
\&gt; O
F1 O
score O
of O
dryer:0.11984230336978431 O
&lt;br O
\&gt; O
Average O
F1 O
score O
of O
all:0.3551037293301434&lt;br O
\&gt; O
MODEL DESCRIPTION AND DEVELOPMENT: &lt;br \&gt;The model development and description task is performed fairly but there are rooms to improve. It is better to give more depth when comparing models’ pros and cons and justify why you chose these modeling techniques to solve the problem in hand.	Sensemaking 1&Impact 1
Moreover, more explanation is expected regarding the model development phase especially in feature selection and hyperparameters tuning.	Sensemaking 1
It is important to assure the readers that you are developing and comparing the models in a fair and robust setting.	Sensemaking 1
&lt;br O
\&gt; O
MODEL EVALUATION AND INFERENCE: &lt;br \&gt;Model evaluation is fine.	Sensemaking 1
More effort is needed for model inference.	Sensemaking 1
&lt;br O
\&gt; O
CODE AND REPORT READIBILITY: &lt;br \&gt;The report is well structured.	Sensemaking 1
The ideas are properly explained.	Sensemaking 1
However, the formatting is not consistent among the theme. There are some confusing subsection titles, such as &amp;quot;dummy variable&amp;quot;, which cannot clearly describe what the section is about.	Sensemaking 1
&lt;br O
\&gt;&lt;br O
\&gt; O
The program is well documented with no redundant codes.	Sensemaking 1
The README file is missing most of the necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc." 60.37	Sensemaking 1

"FINAL O
MARK O
(out O
of O
35): O
26.61&lt;br O
\&gt;LATE O
PENALTY O
APPLIED O
(days): O
0&lt;br O
\&gt;OUTPUT O
MARK O
(out O
of O
15): O
8.78&lt;br O
\&gt; O
------------------- O
COMMENTS O
--------------------&lt;br O
\&gt;OUTPUT O
PERFORMANCE: O
&lt;br O
\&gt;F1 O
score O
of O
ac:0.8894319485312453 O
&lt;br O
\&gt; O
F1 O
score O
of O
ev:0.01172562532536751 O
&lt;br O
\&gt; O
F1 O
score O
of O
oven:0.6472675656493967 O
&lt;br O
\&gt; O
F1 O
score O
of O
wash:0.08020662315300524 O
&lt;br O
\&gt; O
F1 O
score O
of O
dryer:0.12851770525731304 O
&lt;br O
\&gt; O
Average O
F1 O
score O
of O
all:0.3514298935832655&lt;br O
\&gt; O
MODEL DESCRIPTION AND DEVELOPMENT: &lt;br \&gt;Good work, the model description and development task is performed fairly.	Agency 2&Sensemaking 1
It is good that you compared different modeling families with respect to their pros and cons.	Sensemaking 1
More discussion is expected regarding the model development phase and especially on feature selection and how the model hyperparameters are tuned.	Sensemaking 1
&lt;br O
\&gt; O
MODEL EVALUATION AND INFERENCE: &lt;br \&gt;Impressive model evaluation and inference.	Sensemaking 1
Even though DNN is not the best model, the exploration is still significant.	Sensemaking 1
&lt;br O
\&gt; O
CODE AND REPORT READIBILITY: &lt;br \&gt;The report is neat and well structured.	Sensemaking 1
The flow of the ideas is easy to follow.	Sensemaking 1
The communication is effective with the help of graphs and tables.	Sensemaking 1
However, some connections between the tables and the texts are missing. For example, table 7 not only shows the sampling method, it also shows which model has the best performance in that particular label.	Sensemaking 1
You can take advantage of the tables to help summarising your work.	Sensemaking 1
&lt;br O
\&gt;&lt;br O
\&gt; O
The program is well documented with no redundant codes.	Sensemaking 1
The README file includes all necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc." 76.03	Sensemaking 1

"LATE O
PENALTY O
APPLIED O
(days): O
0OUTPUT O
MARK O
(out O
of O
15): O
11.54 O
------------------- O
COMMENTS O
--------------------OUTPUT O
PERFORMANCE: O
F1 O
score O
of O
ac:0.9125109361329834 O
F1 O
score O
of O
ev:0.20745542949756887 O
F1 O
score O
of O
oven:0.6397443346891343 O
F1 O
score O
of O
wash:0.09945169219134052 O
F1 O
score O
of O
dryer:0.15907823824567927 O
Average O
F1 O
score O
of O
all:0.40364812615134127 O
MODEL DESCRIPTION AND DEVELOPMENT: The model development and description task is performed fairly but there are rooms to improve.	Sensemaking 1
It is better to give more depth when comparing models’ pros and cons and justify why you chose these modeling techniques to solve the problem in hand.	Impact 1
Moreover, more explanation is expected regarding the model development phase especially in feature selection and hyperparameters tuning.	Sensemaking 1
It is important to assure the readers that you are developing and comparing the models in a fair and robust setting.	Sensemaking 1
MODEL EVALUATION AND INFERENCE: Well done, the model evaluation and inference for each appliance is impressive.	Agency 2&Sensemaking 1
CODE AND REPORT READIBILITY: The report is well structured. However, there are some informations missing, such as the side by side boxplot mentioned uder section 5.2.	Sensemaking 1
The program is well documented with no redundant codes.	Sensemaking 1
README file is the html page of github page.	Sensemaking 1
The file includes all necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc.}""	Sensemaking 1
data-sheets-userformat=""{2:14594,4:[null,2,16777215],11:3,14:[null,2,0],15:Inconsolata, O
monospace, O
arial, O
sans, O
sans-serif,16:11}"" O
data-sheets-formula=""=SUBSTITUTE(SUBSTITUTE(R[0]C[-1], O
char(10), O
&amp; O
char(10) O
),,&amp;quot;)"">FINAL O
MARK O
(out O
of O
35): O
28.29&lt;br O
\&gt;LATE O
PENALTY O
APPLIED O
(days): O
0&lt;br O
\&gt;OUTPUT O
MARK O
(out O
of O
15): O
11.54&lt;br O
\&gt; O
------------------- O
COMMENTS O
--------------------&lt;br O
\&gt;OUTPUT O
PERFORMANCE: O
&lt;br O
\&gt;F1 O
score O
of O
ac:0.9125109361329834 O
&lt;br O
\&gt; O
F1 O
score O
of O
ev:0.20745542949756887 O
&lt;br O
\&gt; O
F1 O
score O
of O
oven:0.6397443346891343 O
&lt;br O
\&gt; O
F1 O
score O
of O
wash:0.09945169219134052 O
&lt;br O
\&gt; O
F1 O
score O
of O
dryer:0.15907823824567927 O
&lt;br O
\&gt; O
Average O
F1 O
score O
of O
all:0.40364812615134127&lt;br O
\&gt; O
MODEL DESCRIPTION AND DEVELOPMENT: &lt;br \&gt;The model development and description task is performed fairly but there are rooms to improve.	Sensemaking 1
It is better to give more depth when comparing models’ pros and cons and justify why you chose these modeling techniques to solve the problem in hand.	Impact 1
Moreover, more explanation is expected regarding the model development phase especially in feature selection and hyperparameters tuning.	Sensemaking 1
It is important to assure the readers that you are developing and comparing the models in a fair and robust setting.	Sensemaking 1
&lt;br O
\&gt; O
MODEL EVALUATION AND INFERENCE: &lt;br \&gt;Well done, the model evaluation and inference for each appliance is impressive.	Agency 2&Sensemaking 1
&lt;br O
\&gt; O
CODE AND REPORT READIBILITY: &lt;br \&gt;The report is well structured. However, there are some informations missing, such as the side by side boxplot mentioned uder section 5.2.	Sensemaking 1
&lt;br O
\&gt;&lt;br O
\&gt; O
The program is well documented with no redundant codes.	Sensemaking 1
README file is the html page of github page. The file includes all necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc." 80.83	Sensemaking 1

"LATE O
PENALTY O
APPLIED O
(days): O
0OUTPUT O
MARK O
(out O
of O
15): O
4.01 O
------------------- O
COMMENTS O
--------------------OUTPUT O
PERFORMANCE: O
F1 O
score O
of O
ac:0.0 O
F1 O
score O
of O
ev:0.008939213349225266 O
F1 O
score O
of O
oven:0.48075693645313894 O
F1 O
score O
of O
wash:0.16761871538830506 O
F1 O
score O
of O
dryer:0.25219164118246684 O
Average O
F1 O
score O
of O
all:0.18190130127462723 O
MODEL DESCRIPTION AND DEVELOPMENT: The model development and description task is performed fairly but there are rooms to improve.	Sensemaking 1
It is better to give more depth when comparing models’ pros and cons and justify why you chose these modeling techniques to solve the problem in hand.	Impact 1
Moreover, more explanation is expected regarding the model development phase especially in feature selection and hyperparameters tuning.	Sensemaking 1
It is important to assure the readers that you are developing and comparing the models in a fair and robust setting.	Sensemaking 1
MODEL EVALUATION AND INFERENCE: The model evaluation and inference is impressive.	Sensemaking 1
Training and prediction time is also distinctive.	Sensemaking 1
CODE AND REPORT READIBILITY: The report is neat and well structured.	Sensemaking 1
The flow of the ideas is easy to follow.	Sensemaking 1
The communication is effective with the help of graphs and tables.	Sensemaking 1
The program is well documented with no redundant codes.	Sensemaking 1
The README file is missing some necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc.}""	Sensemaking 1
data-sheets-userformat=""{2:14594,4:[null,2,16777215],11:3,14:[null,2,0],15:Inconsolata, O
monospace, O
arial, O
sans, O
sans-serif,16:11}"" O
data-sheets-formula=""=SUBSTITUTE(SUBSTITUTE(R[0]C[-1], O
char(10), O
&amp; O
char(10) O
),,&amp;quot;)"">FINAL O
MARK O
(out O
of O
35): O
21.01&lt;br O
\&gt;LATE O
PENALTY O
APPLIED O
(days): O
0&lt;br O
\&gt;OUTPUT O
MARK O
(out O
of O
15): O
4.01&lt;br O
\&gt;------------------- O
COMMENTS O
--------------------&lt;br O
\&gt;OUTPUT O
PERFORMANCE: O
&lt;br O
\&gt;F1 O
score O
of O
ac:0.0 O
&lt;br O
\&gt;F1 O
score O
of O
ev:0.008939213349225266 O
&lt;br O
\&gt;F1 O
score O
of O
oven:0.48075693645313894 O
&lt;br O
\&gt;F1 O
score O
of O
wash:0.16761871538830506 O
&lt;br O
\&gt;F1 O
score O
of O
dryer:0.25219164118246684 O
&lt;br O
\&gt;Average O
F1 O
score O
of O
all:0.18190130127462723&lt;br O
\&gt; O
MODEL DESCRIPTION AND DEVELOPMENT: &lt;br \&gt;The model development and description task is performed fairly but there are rooms to improve.	Sensemaking 1
It is better to give more depth when comparing models’ pros and cons and justify why you chose these modeling techniques to solve the problem in hand.	Impact 1
Moreover, more explanation is expected regarding the model development phase especially in feature selection and hyperparameters tuning.	Sensemaking 1
It is important to assure the readers that you are developing and comparing the models in a fair and robust setting.	Sensemaking 1
&lt;br O
\&gt; O
MODEL EVALUATION AND INFERENCE: &lt;br \&gt;The model evaluation and inference is impressive.	Sensemaking 1
Training and prediction time is also distinctive.	Sensemaking 1
&lt;br O
\&gt; O
CODE AND REPORT READIBILITY: &lt;br \&gt;The report is neat and well structured.	Sensemaking 1
The flow of the ideas is easy to follow.	Sensemaking 1
The communication is effective with the help of graphs and tables.	Sensemaking 1
&lt;br O
\&gt;&lt;br O
\&gt; O
The program is well documented with no redundant codes.	Sensemaking 1
The README file is missing some necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc." 60.03	Sensemaking 1

"""FINAL O
MARK O
(out O
of O
35): O
27.52&lt;br O
\&gt;LATE O
PENALTY O
APPLIED O
(days): O
0&lt;br O
\&gt;OUTPUT O
MARK O
(out O
of O
15): O
13.11&lt;br O
\&gt;;------------------- O
COMMENTS O
--------------------&lt;br O
\&gt;OUTPUT O
PERFORMANCE: O
&lt;br O
\&gt;F1 O
score O
of O
ac:0.9126051356319278; O
; O
;&lt;br O
\&gt;;F1 O
score O
of O
ev:0.3617571059431524; O
; O
;&lt;br O
\&gt;;F1 O
score O
of O
oven:0.6208967173738992; O
;&lt;br O
\&gt;;F1 O
score O
of O
wash:0.07803180914512924; O
;&lt;br O
\&gt;;F1 O
score O
of O
dryer:0.4633612363168062; O
;&lt;br O
\&gt;;Average O
F1 O
score O
of O
all:0.48733040088218293&lt;br O
\&gt; O
MODEL DESCRIPTION AND DEVELOPMENT: &lt;br \&gt;well done, model development and description is performed well, it is better to have more explanation regarding the model development phase especially in feature selection and hyperparameters tuning.	Agency 2&Sensemaking 1&Impact 1
It is important to assure the readers that you are developing and comparing the models in a fair and robust setting.; about model tuning in the report	Sensemaking 1
&lt;br O
\&gt; O
MODEL EVALUATION AND INFERENCE: &lt;br \&gt;Good evaluation with LSTM and CNN.	Sensemaking 1
More effort can be done for model inference, i.e. which features are important. Since neural networks are black boxes, it would be challenging for you to do inference. However, there are gradient based methods which can show the importance level of the input.	Sensemaking 1
&lt;br O
\&gt; O
CODE AND REPORT READIBILITY: &lt;br \&gt;The report is neat and well structured.	Sensemaking 1
The flow of the ideas is easy to follow.	Sensemaking 1
The communication is effective with the help of graphs and tables.	Sensemaking 1
&lt;br O
\&gt;&lt;br O
\&gt; O
The program is well documented with no redundant codes.	Sensemaking 1
The README file is missing some necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc.""" 78.63	Sensemaking 1

"Penalty applied due to below average contribution	Sensemaking 2
FINAL O
MARK O
(out O
of O
35): O
27.02&lt;br O
\&gt;LATE O
PENALTY O
APPLIED O
(days): O
0&lt;br O
\&gt;OUTPUT O
MARK O
(out O
of O
15): O
10.44&lt;br O
\&gt; O
------------------- O
COMMENTS O
--------------------&lt;br O
\&gt;OUTPUT O
PERFORMANCE: O
&lt;br O
\&gt;F1 O
score O
of O
ac:0.9123460169723515 O
&lt;br O
\&gt; O
F1 O
score O
of O
ev:0.07425919314530526 O
&lt;br O
\&gt; O
F1 O
score O
of O
oven:0.6285879965207306 O
&lt;br O
\&gt; O
F1 O
score O
of O
wash:0.08999046711153479 O
&lt;br O
\&gt; O
F1 O
score O
of O
dryer:0.18402555910543134 O
&lt;br O
\&gt; O
Average O
F1 O
score O
of O
all:0.3778418465710707&lt;br O
\&gt; O
MODEL DESCRIPTION AND DEVELOPMENT: &lt;br \&gt;Good work, the model description and development task is performed fairly.	Agency 2&Sensemaking 1
It is good that you compared different modeling families with respect to their pros and cons.	Sensemaking 1
More discussion is expected regarding the model development phase and especially on feature selection and how the model hyperparameters are tuned.	Sensemaking 1
&lt;br O
\&gt; O
MODEL EVALUATION AND INFERENCE: &lt;br \&gt;Significant model evaluation and inference.	Sensemaking 1
the plots are very clear.	Sensemaking 1
&lt;br O
\&gt; O
CODE AND REPORT READIBILITY: &lt;br \&gt;The report is well structured.	Sensemaking 1
However, there are some important information missing, such as the F1-scores and the choice of final models on different labels, as well as the hyperparameters in the final models.	Sensemaking 1
&lt;br O
\&gt;&lt;br O
\&gt; O
The program is well documented with no redundant codes.	Sensemaking 1
The README file is missing some necessary information, such as descriptions of the files in the directory, the environmental setup, libraries used and their versions etc." 71.43	Sensemaking 1

"FINAL O
MARK O
(OUT O
OF O
100): O
47APPLIED O
LATE O
PENALTY O
(DAYS): O
1 O
DaysOther O
Penalties O
(5 O
marks O
worth): O
None---------------------TASK O
1 O
Mark O
(out O
of O
60): O
24.67 O
Task 1 Comments: Good job in find suburb.	Agency 2
However, - incorrect way to save the min stops - should compare the difference between arrive time and departure time to find the min to CBD and transfer flag - Only folder 2 was required as it contains train information.	Sensemaking 1&Impact 1
Please refer to the HTML feedback file on Moodle for more detailed breakdown of your task	Agency 1
1.---------------------Task O
2 O
mark O
(out O
of O
20): O
15 O
Task 2 Comments: - should Performing EDA beforehand to see the shape of the variables and the relationship among the variables ---------------------	Impact 1
Method O
and O
Documentation O
mark O
(out O
of O
20): O
17 O
Documentation comments: Well Done" 47	Agency 2

"General Feedback: To solve the assignment and achieve the correct output, students need to follow these steps:Dirty data:1) Use missing data with no missing value records (or cleaned dirty data) to find the items price list using linear system of equations (np.alg.solve). 2) Check that order_price matches shopping_cart and fix it if it doesn't match. 3) FIx the date to be in the DD/MM/YYYY format using strptime functions or other method. 4) Fix syntactic errors in customer lat and long (ecords where lat and lon are swapped). The specs mention that all the lats and longs are in Melbourne. 5) Based on customer lat and long, find the distance between the customer and the nearest storehouse (using Haversine distance) . Compare to given value and fix if needed. 6) Fix the time to be in the given format if needed. 7) Fix syntactic issues in parcel_size and check if there are semantic issues (if any) by maybe checking the cross-tab with shopping_cart size in either missing_data or outliers data.8) Fix storehouse id by checking the cross-tab between storehouse_id and nearest_storehouse in either missing_data or outliers data. 9) Verify that isLoyaltyProgram has no issues by checking the residuals of the linear models prediction. (optional)Missing Data:10) Impute order_price based on shopping_cart and the obtained items price list. 11) Use the linear model to impute delivery_cost . The linear model should be fitted to predict delivery_cost based on season, nearest_storehouse, and distance. (season and storehouse should be converted to dummy variables first because they are categorical)Outlier Data:Many ways can be used, here is one possible recommended method:12) Concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier) 13) Use the linear model (trained earlier) to predict all delivery_costs and calculate the residuals 14) Use 2/3sigma rule or 1.5 IQR on the residuals to identify and remove the outlier records.	Impact 1
Specific Feedback:Output Results:Your Dirty Data Mark (out of 30) is: 15.33Your Missing Data Mark (out of 15) is: 10.43Your Outlier Mark (out of 15) is: 12.35Other Penalties: NoneTotal marks deducted: 0Your Final Output Mark (out of 60) is: 38Please refer to your HTML feedback report for a more detailed breakdown of the output marks	Sensemaking 2&Agency 1
Methodology and Documentation: Your Methodology Mark (out of 25) is: 21Your Documentation Mark (out of 15) is: 15Your tutor comments are: Outlier Data:- before deleting the outliers should concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier), then use another method to confirm those outliers e.g( use the linear models (trained earlier) to predict all delivery_costs and calculate the residuals )	Sensemaking 2&Impact 1
Your Late Penalty marks: 0Your Final Mark (out of 100) is: 74" 74	Sensemaking 2

"Total O
mark O
before O
penalty O
(out O
of O
100): O
45.06Late O
submission O
penalty O
(1 O
days): O
10Total O
mark O
after O
penalty O
(out O
of O
100): O
35.06---------------------------Task1 O
total O
mark O
(out O
of O
100): O
50.85Task1 O
csv O
output O
mark O
(out O
of O
15): O
0 O
Parsing Error: Error tokenizing data. C error: Expected 4 fields in line 124668, saw 5	Sensemaking 1
Task1 O
XML O
output O
mark O
(out O
of O
35): O
2.85 O
Please refer to HTML feedback file for more details about your CSV and XML mismatches (if file(s) are parsable)	Agency 1
Task1 O
methodology O
mark O
(out O
of O
25): O
23 O
Tutor Comment: Good effort for task 1	Agency 2
- the code could be improved further in terms of efficiency and readability	Sensemaking 1
1. should also use the double quation for the uuid, text, author and published while save the data to csv to avoid the content been splitted by comma	Impact 1
2. should deal with those special characters before write to xml, and also it's not only one type of special characters	Impact 1
Task1 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor Comment: Good documentation	Sensemaking 1
. O
---------------------------Task2 O
mark O
(out O
of O
100): O
38Task2 O
output O
mark O
(out O
of O
50): O
0Vocab O
Accuracy O
(%): O
0 O
CountVec O
Accuracy O
(%): O
0 O
Parsing Error: [Errno 2] No such file or directory: 'student_output/30730856/30730856_countVec.txt'	Sensemaking 1
Unigram O
Accuracy O
(%): O
0 O
Bigram O
Accuracy O
(%): O
0 O
Task2 O
methodology O
mark O
(out O
of O
25): O
13 O
Tutor Comment: Correct order for VOCAB and COUNTVEC: 1.Reading files with appropriate encoding 2.case normalisation 3.bigrams extraction using PMI assoc measure 4.stopword, rare tokens, length 3 (the order does not matter for these three) 5.stemming (not bigrams) 6.sparse file generation Correct order for ""100_UNI"" file: 1.case normalisation 2.CI stopword, length 3 (the order does not matter for these three) 3.stemming Correct order for ""100_BI"" file: 1.case normalisation 2.CI stopword, length 3, 3.bigrams calculation using ngrams() function. 4 Sorting using FreqDist or other	Sensemaking 1
Task2 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor comment: Good documentation with proper structure and explanation.---------------------------" 35	Sensemaking 1

"FINAL O
MARK O
(OUT O
OF O
100): O
68APPLIED O
LATE O
PENALTY O
(DAYS): O
2 O
DaysOther O
Penalties O
(5 O
marks O
worth): O
None---------------------TASK O
1 O
Mark O
(out O
of O
60): O
50.99 O
Task 1 Comments: Well Done. But only folder 2 was required as it contains train information. Because of this, the train ids are differently selected.	Agency 2&Sensemaking 1
Please refer to the HTML feedback file on Moodle for more detailed breakdown of your task	Agency 1
1.---------------------Task O
2 O
mark O
(out O
of O
20): O
20Task O
2 O
Comments: O
Well O
Done---------------------Method O
and O
Documentation O
mark O
(out O
of O
20): O
17 O
Documentation comments: Well Done.	Agency 2
Could have provided inline comments to explain the code." 68	Sensemaking 1

"Total O
mark O
before O
penalty O
(out O
of O
100): O
60.84Late O
submission O
penalty O
(0 O
days): O
0Total O
mark O
after O
penalty O
(out O
of O
100): O
60.84---------------------------Task1 O
total O
mark O
(out O
of O
100): O
55.85Task1 O
csv O
output O
mark O
(out O
of O
15): O
8.85 O
Task1 O
XML O
output O
mark O
(out O
of O
35): O
0 O
Parsing Error: not well-formed (invalid token): line 7, column 4856Please refer to HTML feedback file for more details about your CSV and XML mismatches (if file(s) are parsable)	Sensemaking 1&Agency 1
Task1 O
methodology O
mark O
(out O
of O
25): O
22 O
Tutor Comment: Good effort for task 1	Agency 2
- the code could be improved further in terms of efficiency and readability1. all the required text should be captured at one time, rather than capture it seperately e.g one for xml, one for csv 2. would be better to store the data into the different dictionary when you captured required content, and each dictionary contain only one uuid, author, published, text as the keys3.the way you wrote csv have some issue, All the text should be enclosed within double quotes (“ Text ”), otherwise comma will separate the text into another cell.	Impact 1
Task1 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor Comment: Good documentation	Sensemaking 1
. O
---------------------------Task2 O
mark O
(out O
of O
100): O
66.93Task2 O
output O
mark O
(out O
of O
50): O
27.43Vocab O
Accuracy O
(%): O
73.94 O
CountVec O
Accuracy O
(%): O
2.88 O
Unigram O
Accuracy O
(%): O
75.7 O
Bigram O
Accuracy O
(%): O
70.27 O
Task2 O
methodology O
mark O
(out O
of O
25): O
14.5 O
Tutor Comment: Correct order for VOCAB and COUNTVEC: 1.Reading files with appropriate encoding 2.case normalisation 3.bigrams extraction using PMI assoc measure 4.stopword, rare tokens, length 3 (the order does not matter for these three) 5.stemming (not bigrams) 6.sparse file generation Correct order for ""100_UNI"" file: 1.case normalisation 2.CI stopword, length 3 (the order does not matter for these three) 3.stemming Correct order for ""100_BI"" file: 1.case normalisation 2.CI stopword, length 3, 3.bigrams calculation using ngrams() function. 4 Sorting using FreqDist or other	Sensemaking 1
Task2 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor comment: Good documentation with proper structure and explanation.---------------------------" 61	Sensemaking 1

"Total O
mark O
before O
penalty O
(out O
of O
100): O
36.47Late O
submission O
penalty O
(2 O
days): O
20Total O
mark O
after O
penalty O
(out O
of O
100): O
16.47---------------------------Task1 O
total O
mark O
(out O
of O
100): O
33.5Task1 O
csv O
output O
mark O
(out O
of O
15): O
0 O
Parsing Error: Error tokenizing data. C error: Expected 6 fields in line 5, saw 7	Sensemaking 1
Task1 O
XML O
output O
mark O
(out O
of O
35): O
0 O
Parsing Error: mismatched tag: line 163, column 50Please refer to HTML feedback file for more details about your CSV and XML mismatches (if file(s) are parsable)	Sensemaking 1&Agency 1
Task1 O
methodology O
mark O
(out O
of O
25): O
8.5 O
Tutor Comment: Good effort for task 1 - the code could be improved further in terms of efficiency and readability1. should use a loop to open all the files at once 2. You have used eval() function or treated the input data as dictionary to extract the information. We believe that, it is always good to think outside of the box and come up with the simplest correct solution. However, as stated in the assignment specs, one of the requirements of the assignment is to ""design an efficient regular expression to extract the information"". Therefore, while we accept your output and do not deduct anymark from the output marks, you will loose the mark associated to designing the regex in the methodology section.3. should also use the double quation for the uuid, author, and oublished while save the data to csv to avoid the content been splitted by comma4. when write the file, should try to avoid open and close it multiple times	Agency 2&Impact 1
Task1 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor Comment: Good documentation	Sensemaking 1
. O
---------------------------Task2 O
mark O
(out O
of O
100): O
40.11Task2 O
output O
mark O
(out O
of O
50): O
2.11Vocab O
Accuracy O
(%): O
0 O
CountVec O
Accuracy O
(%): O
0 O
Unigram O
Accuracy O
(%): O
20.27 O
Bigram O
Accuracy O
(%): O
1.65 O
Task2 O
methodology O
mark O
(out O
of O
25): O
13 O
Tutor Comment: Correct order for VOCAB and COUNTVEC: 1.Reading files with appropriate encoding 2.case normalisation 3.bigrams extraction using PMI assoc measure 4.stopword, rare tokens, length 3 (the order does not matter for these three) 5.stemming (not bigrams) 6.sparse file generation Correct order for ""100_UNI"" file: 1.case normalisation 2.CI stopword, length 3 (the order does not matter for these three) 3.stemming Correct order for ""100_BI"" file: 1.case normalisation 2.CI stopword, length 3, 3.bigrams calculation using ngrams() function. 4 Sorting using FreqDist or other	Sensemaking 1
Task2 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor comment: Good documentation with proper structure and explanation. Could have added summary & reference section.---------------------------" 16	Sensemaking 1

"Total O
mark O
before O
penalty O
(out O
of O
100): O
55.83Late O
submission O
penalty O
(0 O
days): O
0Total O
mark O
after O
penalty O
(out O
of O
100): O
55.83---------------------------Task1 O
total O
mark O
(out O
of O
100): O
69.57Task1 O
csv O
output O
mark O
(out O
of O
15): O
0 O
Parsing Error: Error tokenizing data. C error: Expected 5 fields in line 6, saw 6	Sensemaking 1
Task1 O
XML O
output O
mark O
(out O
of O
35): O
21.57 O
Please refer to HTML feedback file for more details about your CSV and XML mismatches (if file(s) are parsable)	Agency 1
Task1 O
methodology O
mark O
(out O
of O
25): O
23Tutor Comment: Good effort for task 1	Agency 2
- the code could be improved further in terms of efficiency and readability1. Regex used may not be enough to extract only required info - could be improved further by better use of capturing and non-capturing groups.2. the way you wrote csv have some issue, All the text should be enclosed within double quotes (“ Text ”), otherwise comma will separate the text into another cell.	Impact 1
Task1 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor Comment: Good documentation	Sensemaking 1
. O
---------------------------Task2 O
mark O
(out O
of O
100): O
39.04Task2 O
output O
mark O
(out O
of O
50): O
4.04Vocab O
Accuracy O
(%): O
0 O
CountVec O
Accuracy O
(%): O
1.7 O
Unigram O
Accuracy O
(%): O
38.69 O
Bigram O
Accuracy O
(%): O
0 O
Task2 O
methodology O
mark O
(out O
of O
25): O
11 O
Tutor Comment: Correct order for VOCAB and COUNTVEC: 1.Reading files with appropriate encoding 2.case normalisation 3.bigrams extraction using PMI assoc measure 4.stopword, rare tokens, length 3 (the order does not matter for these three) 5.stemming (not bigrams) 6.sparse file generation Correct order for ""100_UNI"" file: 1.case normalisation 2.CI stopword, length 3 (the order does not matter for these three) 3.stemming Correct order for ""100_BI"" file: 1.case normalisation 2.CI stopword, length 3, 3.bigrams calculation using ngrams() function. 4 Sorting using FreqDist or other	Sensemaking 1
Task2 O
documentation O
mark O
(out O
of O
25): O
24 O
Tutor comment: Good documentation with proper structure and explanation. ---------------------------" 56	Sensemaking 1

"FINAL O
MARK O
(OUT O
OF O
100): O
46APPLIED O
LATE O
PENALTY O
(DAYS): O
2 O
DaysOther O
Penalties O
(5 O
marks O
worth): O
None---------------------TASK O
1 O
Mark O
(out O
of O
60): O
33.52 O
Task 1 Comments: Good work, But the calculation for travel min is wrong. The distance should be in kms not meters.	Agency 2&Sensemaking 1&Impact 1
Please refer to the HTML feedback file on Moodle for more detailed breakdown of your task 1	Agency 1
.---------------------Task O
2 O
mark O
(out O
of O
20): O
16 O
Task 2 Comments: Good work, should perform the EDA before and scaling/transformation	Agency 2&Impact 1
.---------------------Method O
and O
Documentation O
mark O
(out O
of O
20): O
16 O
Documentation comments: Well Done" 46	Agency 2

"Total O
mark O
before O
penalty O
(out O
of O
100): O
77.41Late O
submission O
penalty O
(0 O
days): O
0Total O
mark O
after O
penalty O
(out O
of O
100): O
77.41---------------------------Task1 O
total O
mark O
(out O
of O
100): O
85.33Task1 O
csv O
output O
mark O
(out O
of O
15): O
14.31 O
Task1 O
XML O
output O
mark O
(out O
of O
35): O
32.01 O
Please refer to HTML feedback file for more details about your CSV and XML mismatches (if file(s) are parsable)	Agency 1
Task1 O
methodology O
mark O
(out O
of O
25): O
14 O
Tutor Comment: Good effort for task 1	Agency 2
- the code could be improved further in terms of efficiency and readability1. You have used eval() function or treated the input data as dictionary to extract the information. We believe that, it is always good to think outside of the box and come up with the simplest correct solution. However, as stated in the assignment specs, one of the requirements of the assignment is to ""design an efficient regular expression to extract the information"". Therefore, while we accept your output and do not deduct anymark from the output marks, you will loose the mark associated to designing the regex in the methodology section.2. should also use the double quation for the uuid, and published while save the data to csv to avoid the content been splitted by comma	Impact 1
Task1 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor Comment: Good documentation.	Sensemaking 1
---------------------------Task2 O
mark O
(out O
of O
100): O
67.73Task2 O
output O
mark O
(out O
of O
50): O
28.73Vocab O
Accuracy O
(%): O
77.71 O
CountVec O
Accuracy O
(%): O
92.11 O
Unigram O
Accuracy O
(%): O
2.04 O
Bigram O
Accuracy O
(%): O
72.49 O
Task2 O
methodology O
mark O
(out O
of O
25): O
14 O
Tutor Comment: Correct order for VOCAB and COUNTVEC: 1.Reading files with appropriate encoding 2.case normalisation 3.bigrams extraction using PMI assoc measure 4.stopword, rare tokens, length 3 (the order does not matter for these three) 5.stemming (not bigrams) 6.sparse file generation Correct order for ""100_UNI"" file: 1.case normalisation 2.CI stopword, length 3 (the order does not matter for these three) 3.stemming Correct order for ""100_BI"" file: 1.case normalisation 2.CI stopword, length 3, 3.bigrams calculation using ngrams() function. 4 Sorting using FreqDist or other	Sensemaking 1
Task2 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor comment: Good documentation with proper structure and explanation. ---------------------------" 77	Sensemaking 1

"General Feedback: To solve the assignment and achieve the correct output, students need to follow these steps:Dirty data:1) Use missing data with no missing value records (or cleaned dirty data) to find the items price list using linear system of equations (np.alg.solve). 2) Check that order_price matches shopping_cart and fix it if it doesn't match. 3) FIx the date to be in the DD/MM/YYYY format using strptime functions or other method. 4) Fix syntactic errors in customer lat and long (ecords where lat and lon are swapped). The specs mention that all the lats and longs are in Melbourne. 5) Based on customer lat and long, find the distance between the customer and the nearest storehouse (using Haversine distance) . Compare to given value and fix if needed. 6) Fix the time to be in the given format if needed. 7) Fix syntactic issues in parcel_size and check if there are semantic issues (if any) by maybe checking the cross-tab with shopping_cart size in either missing_data or outliers data.8) Fix storehouse id by checking the cross-tab between storehouse_id and nearest_storehouse in either missing_data or outliers data. 9) Verify that isLoyaltyProgram has no issues by checking the residuals of the linear models prediction. (optional)Missing Data:10) Impute order_price based on shopping_cart and the obtained items price list. 11) Use the linear model to impute delivery_cost . The linear model should be fitted to predict delivery_cost based on season, nearest_storehouse, and distance. (season and storehouse should be converted to dummy variables first because they are categorical)Outlier Data:Many ways can be used, here is one possible recommended method:12) Concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier) 13) Use the linear model (trained earlier) to predict all delivery_costs and calculate the residuals 14) Use 2/3sigma rule or 1.5 IQR on the residuals to identify and remove the outlier records.	Impact 1
Specific O
Feedback:Output O
Results:Your O
Dirty O
Data O
Mark O
(out O
of O
30) O
is: O
17Your O
Missing O
Data O
Mark O
(out O
of O
15) O
is: O
14.35Your O
Outlier O
Mark O
(out O
of O
15) O
is: O
13.24Other O
Penalties: O
NoneTotal O
marks O
deducted: O
0Your O
Final O
Output O
Mark O
(out O
of O
60) O
is: O
45 O
Please refer to your HTML feedback report for a more detailed breakdown of the output marks	Agency 1
Methodology O
and O
Documentation: O
Your O
Methodology O
Mark O
(out O
of O
25) O
is: O
20.5Your O
Documentation O
Mark O
(out O
of O
15) O
is: O
13.5 O
Your tutor comments are: Dirty data:- could verify that isLoyaltyProgram has no issues by checking the residuals of the linear models prediction.Outlier Data:- before deleting the outliers should concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier), then use another method to confirm those outliers e.g( use the linear models (trained earlier) to predict all delivery_costs and calculate the residuals )	Sensemaking 1&Impact 1
Documentation: -could add more explanation regarding how to solve those issues rather than just provide the headings.	Impact 1
Your Late Penalty marks: 10Your Final Mark (out of 100) is: 69" 69	Sensemaking 2

"Total O
mark O
before O
penalty O
(out O
of O
100): O
73.04Late O
submission O
penalty O
(0 O
days): O
0Additional O
Penalty O
(5%): O
3.65 O
Reason: O
Task O
2 O
files O
are O
misnamedTotal O
mark O
after O
penalty O
(out O
of O
100): O
69.38---------------------------Task1 O
total O
mark O
(out O
of O
100): O
74.28Task1 O
csv O
output O
mark O
(out O
of O
15): O
10.89 O
Task1 O
XML O
output O
mark O
(out O
of O
35): O
25.39 O
Please refer to HTML feedback file for more details about your CSV and XML mismatches (if file(s) are parsable)	Agency 1
Task1 O
methodology O
mark O
(out O
of O
25): O
13 O
Tutor Comment: Good effort for task 1	Agency 2
- O
the code could be improved further in terms of efficiency and readability1. You have used eval() function or treated the input data as dictionary to extract the information. We believe that, it is always good to think outside of the box and come up with the simplest correct solution. However, as stated in the assignment specs, one of the requirements of the assignment is to ""design an efficient regular expression to extract the information"". Therefore, while we accept your output and do not deduct anymark from the output marks, you will loose the mark associated to designing the regex in the methodology section.2. should also use the double quation for the uuid, author, and oublished while save the data to csv to avoid the content been splitted by comma3. Non-English tweets should be removed after decoding the surrogate pairs.	Impact 1
Task1 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor Comment: Good documentation	Sensemaking 1
. O
---------------------------Task2 O
mark O
(out O
of O
100): O
71.52Task2 O
output O
mark O
(out O
of O
50): O
32.52Vocab O
Accuracy O
(%): O
78.06 O
CountVec O
Accuracy O
(%): O
91.95 O
Unigram O
Accuracy O
(%): O
53.33 O
Bigram O
Accuracy O
(%): O
69.48 O
Task2 O
methodology O
mark O
(out O
of O
25): O
14 O
Tutor Comment: Correct order for VOCAB and COUNTVEC: 1.Reading files with appropriate encoding 2.case normalisation 3.bigrams extraction using PMI assoc measure 4.stopword, rare tokens, length 3 (the order does not matter for these three) 5.stemming (not bigrams) 6.sparse file generation Correct order for ""100_UNI"" file: 1.case normalisation 2.CI stopword, length 3 (the order does not matter for these three) 3.stemming Correct order for ""100_BI"" file: 1.case normalisation 2.CI stopword, length 3, 3.bigrams calculation using ngrams() function. 4 Sorting using FreqDist or other	Sensemaking 1
Task2 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor comment: Good documentation with proper structure and explanation.	Sensemaking 1
---------------------------" O
69 O

"FINAL O
MARK O
(OUT O
OF O
100): O
61APPLIED O
LATE O
PENALTY O
(DAYS): O
DaysOther O
Penalties O
(5 O
marks O
worth): O
None---------------------TASK O
1 O
Mark O
(out O
of O
60): O
29.55 O
Task 1 Comments: Good job. However: - Only folder 2 was required as it contains train information.Please refer to the HTML feedback file on Moodle for more detailed breakdown of your task 1	Agency 2&Sensemaking 1&Agency 1
.---------------------Task O
2 O
mark O
(out O
of O
20): O
12 O
Task 2 Comments: - did try to perform the EDA, but could improve by also checking the distribution/ score before and after the transformation	Sensemaking 1&Impact 1
. O
- O
should also use scaling to see the effects	Impact 1
---------------------Method O
and O
Documentation O
mark O
(out O
of O
20): O
19 O
Documentation comments: Well Done" 61	Agency 2

"General Feedback: To solve the assignment and achieve the correct output, students need to follow these steps:Dirty data:1) Use missing data with no missing value records (or cleaned dirty data) to find the items price list using linear system of equations (np.alg.solve). 2) Check that order_price matches shopping_cart and fix it if it doesn't match. 3) FIx the date to be in the DD/MM/YYYY format using strptime functions or other method. 4) Fix syntactic errors in customer lat and long (ecords where lat and lon are swapped). The specs mention that all the lats and longs are in Melbourne. 5) Based on customer lat and long, find the distance between the customer and the nearest storehouse (using Haversine distance) . Compare to given value and fix if needed. 6) Fix the time to be in the given format if needed. 7) Fix syntactic issues in parcel_size and check if there are semantic issues (if any) by maybe checking the cross-tab with shopping_cart size in either missing_data or outliers data.8) Fix storehouse id by checking the cross-tab between storehouse_id and nearest_storehouse in either missing_data or outliers data. 9) Verify that isLoyaltyProgram has no issues by checking the residuals of the linear models prediction. (optional)Missing Data:10) Impute order_price based on shopping_cart and the obtained items price list. 11) Use the linear model to impute delivery_cost . The linear model should be fitted to predict delivery_cost based on season, nearest_storehouse, and distance. (season and storehouse should be converted to dummy variables first because they are categorical)Outlier Data:Many ways can be used, here is one possible recommended method:12) Concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier) 13) Use the linear model (trained earlier) to predict all delivery_costs and calculate the residuals 14) Use 2/3sigma rule or 1.5 IQR on the residuals to identify and remove the outlier records.	Impact 1
Specific O
Feedback:Output O
Results:Your O
Dirty O
Data O
Mark O
(out O
of O
30) O
is: O
22Your O
Missing O
Data O
Mark O
(out O
of O
15) O
is: O
15Your O
Outlier O
Mark O
(out O
of O
15) O
is: O
12.35Other O
Penalties: O
NoneTotal O
marks O
deducted: O
0Your O
Final O
Output O
Mark O
(out O
of O
60) O
is: O
49 O
Please refer to your HTML feedback report for a more detailed breakdown of the output marks	Agency 1
Methodology O
and O
Documentation: O
Your O
Methodology O
Mark O
(out O
of O
25) O
is: O
20Your O
Documentation O
Mark O
(out O
of O
15) O
is: O
15 O
Your tutor comments are: For Dirty data, - ""Time"" column, the condition should be &gt;24 not &gt;=24, after 23:59:59, it will be 0:00:00, not 24:59:59	Impact 1
. O
- O
""isloyalProgram"" is not check for errors.	Sensemaking 1
For Outlier data, - Could have combined all the data (cleaned_dirty, missing, outlier) to detect the outlier and then used the linear model for further detection.	Impact 1
Your O
Late O
Penalty O
marks: O
0Your O
Final O
Mark O
(out O
of O
100) O
is: O
84 O
As a result of academic misconduct, the final mark changed to 0" 0	Sensemaking 2

FINAL O
MARK O
(OUT O
OF O
100): O
91APPLIED O
LATE O
PENALTY O
(DAYS): O
DaysOther O
Penalties O
(5 O
marks O
worth): O
None---------------------TASK O
1 O
Mark O
(out O
of O
60): O
52.13 O
Task 1 Comments: Well Done. But only folder 2 was required as it contains train information.Please refer to the HTML feedback file on Moodle for more detailed breakdown of your task 1	Agency 2&Sensemaking 1&Agency 1
.---------------------Task O
2 O
mark O
(out O
of O
20): O
20 O
Task 2 Comments: Well Done	Agency 2
---------------------Method O
and O
Documentation O
mark O
(out O
of O
20): O
19 O
Documentation comments: Well Done 91	Agency 2

"General Feedback: To solve the assignment and achieve the correct output, students need to follow these steps:Dirty data:1) Use missing data with no missing value records (or cleaned dirty data) to find the items price list using linear system of equations (np.alg.solve). 2) Check that order_price matches shopping_cart and fix it if it doesn't match. 3) FIx the date to be in the DD/MM/YYYY format using strptime functions or other method. 4) Fix syntactic errors in customer lat and long (ecords where lat and lon are swapped). The specs mention that all the lats and longs are in Melbourne. 5) Based on customer lat and long, find the distance between the customer and the nearest storehouse (using Haversine distance) . Compare to given value and fix if needed. 6) Fix the time to be in the given format if needed. 7) Fix syntactic issues in parcel_size and check if there are semantic issues (if any) by maybe checking the cross-tab with shopping_cart size in either missing_data or outliers data.8) Fix storehouse id by checking the cross-tab between storehouse_id and nearest_storehouse in either missing_data or outliers data. 9) Verify that isLoyaltyProgram has no issues by checking the residuals of the linear models prediction. (optional)Missing Data:10) Impute order_price based on shopping_cart and the obtained items price list. 11) Use the linear model to impute delivery_cost . The linear model should be fitted to predict delivery_cost based on season, nearest_storehouse, and distance. (season and storehouse should be converted to dummy variables first because they are categorical)Outlier Data:Many ways can be used, here is one possible recommended method:12) Concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier) 13) Use the linear model (trained earlier) to predict all delivery_costs and calculate the residuals 14) Use 2/3sigma rule or 1.5 IQR on the residuals to identify and remove the outlier records.	Impact 1
Specific O
Feedback:Output O
Results:Your O
Dirty O
Data O
Mark O
(out O
of O
30) O
is: O
22Your O
Missing O
Data O
Mark O
(out O
of O
15) O
is: O
13.13Your O
Outlier O
Mark O
(out O
of O
15) O
is: O
9.71Other O
Penalties: O
NoneTotal O
marks O
deducted: O
0Your O
Final O
Output O
Mark O
(out O
of O
60) O
is: O
45 O
Please refer to your HTML feedback report for a more detailed breakdown of the output marks	Agency 1
Methodology O
and O
Documentation: O
Your O
Methodology O
Mark O
(out O
of O
25) O
is: O
19Your O
Documentation O
Mark O
(out O
of O
15) O
is: O
15 O
Your tutor comments are: Missing data	Sensemaking 1
:- O
Use the linear model to impute delivery_cost . First, season needs to be calculated, and then season and storehouse attributes should be converted to dummy variables before fitting a model. Train/validation set should be used to verify the model has a reasonable score (~97%)outliers (would be better to follow the below steps):-Concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier) - Use the linear models (trained earlier) to predict all delivery_costs and calculate the residuals - Use 3sigma rule or 1.5 IQR on the residuals to identify and remove the outlier records. or other way around for step 2 and 3	Impact 1
Your Late Penalty marks: 0Your Final Mark (out of 100) is: 79" 79	Sensemaking 2

"FINAL O
MARK O
(OUT O
OF O
100): O
55APPLIED O
LATE O
PENALTY O
(DAYS): O
DaysOther O
Penalties O
(5 O
marks O
worth): O
None---------------------TASK O
1 O
Mark O
(out O
of O
60): O
24.61 O
Task 1 Comments: - Only folder 2 was required as it contains train information	Sensemaking 1
.- O
according to your code, should use shortestdistance to get the id	Impact 1
Please refer to the HTML feedback file on Moodle for more detailed breakdown of your task 1	Agency 1
.---------------------Task O
2 O
mark O
(out O
of O
20): O
12 O
Task 2 Comments: - should include data transformation such as boxcox transformation, or power transformation etc	Impact 1
. O
---------------------Method O
and O
Documentation O
mark O
(out O
of O
20): O
18 O
Documentation comments: Well Done" 55	Agency 2

"General Feedback: To solve the assignment and achieve the correct output, students need to follow these steps:Dirty data:1) Use missing data with no missing value records (or cleaned dirty data) to find the items price list using linear system of equations (np.alg.solve). 2) Check that order_price matches shopping_cart and fix it if it doesn't match. 3) FIx the date to be in the DD/MM/YYYY format using strptime functions or other method. 4) Fix syntactic errors in customer lat and long (ecords where lat and lon are swapped). The specs mention that all the lats and longs are in Melbourne. 5) Based on customer lat and long, find the distance between the customer and the nearest storehouse (using Haversine distance) . Compare to given value and fix if needed. 6) Fix the time to be in the given format if needed. 7) Fix syntactic issues in parcel_size and check if there are semantic issues (if any) by maybe checking the cross-tab with shopping_cart size in either missing_data or outliers data.8) Fix storehouse id by checking the cross-tab between storehouse_id and nearest_storehouse in either missing_data or outliers data. 9) Verify that isLoyaltyProgram has no issues by checking the residuals of the linear models prediction. (optional)Missing Data:10) Impute order_price based on shopping_cart and the obtained items price list. 11) Use the linear model to impute delivery_cost . The linear model should be fitted to predict delivery_cost based on season, nearest_storehouse, and distance. (season and storehouse should be converted to dummy variables first because they are categorical)Outlier Data:Many ways can be used, here is one possible recommended method:12) Concatenate all three datasets into a single one (cleaned_dirty, imputed_missing, outlier) 13) Use the linear model (trained earlier) to predict all delivery_costs and calculate the residuals 14) Use 2/3sigma rule or 1.5 IQR on the residuals to identify and remove the outlier records.	Impact 1
Specific O
Feedback:Output O
Results:Your O
Dirty O
Data O
Mark O
(out O
of O
30) O
is: O
30Your O
Missing O
Data O
Mark O
(out O
of O
15) O
is: O
15Your O
Outlier O
Mark O
(out O
of O
15) O
is: O
10.59Other O
Penalties: O
NoneTotal O
marks O
deducted: O
0Your O
Final O
Output O
Mark O
(out O
of O
60) O
is: O
56 O
Please refer to your HTML feedback report for a more detailed breakdown of the output marks	Agency 1
Methodology O
and O
Documentation: O
Your O
Methodology O
Mark O
(out O
of O
25) O
is: O
21Your O
Documentation O
Mark O
(out O
of O
15) O
is: O
15 O
Your tutor comments are: For Outlier data, - Could have combined all the data (cleaned_dirty, missing, outlier) to detect the outlier and use the linear model for the further detection.	Impact 1
Your Late Penalty marks: 0Your Final Mark (out of 100) is: 92" 92	Sensemaking 2

"Total O
mark O
before O
penalty O
(out O
of O
100): O
42.5Late O
submission O
penalty O
(0 O
days): O
0Total O
mark O
after O
penalty O
(out O
of O
100): O
42.5---------------------------Task1 O
total O
mark O
(out O
of O
100): O
47Task1 O
csv O
output O
mark O
(out O
of O
15): O
0 O
Parsing Error: Error tokenizing data. C error: Expected 4 fields in line 14, saw 10	Sensemaking 1
Task1 O
XML O
output O
mark O
(out O
of O
35): O
0 O
Parsing Error: not well-formed (invalid token): line 49, column 2339	Sensemaking 1
Please refer to HTML feedback file for more details about your CSV and XML mismatches (if file(s) are parsable)	Agency 1
Task1 O
methodology O
mark O
(out O
of O
25): O
22 O
Tutor Comment: Good effort for task 1 - the code could be improved further in terms of efficiency and readability	Impact 1
1. should use a loop to open all the files at once	Impact 1
2. should also use the double quation for the uuid, author, and oublished while save the data to csv to avoid the content been splitted by comma	Impact 1
Task1 O
documentation O
mark O
(out O
of O
25): O
25 O
Tutor Comment: Good documentation	Sensemaking 1
. O
---------------------------Task2 O
mark O
(out O
of O
100): O
37Task2 O
output O
mark O
(out O
of O
50): O
0Vocab O
Accuracy O
(%): O
0 O
Parsing Error: [Errno 2] No such file or directory: 'student_output/26915685/26915685_vocab.txt'CountVec	Sensemaking 1
Accuracy O
(%): O
0 O
Parsing Error: [Errno 2] No such file or directory: 'student_output/26915685/26915685_vocab.txt	Sensemaking 1
'Unigram O
Accuracy O
(%): O
0 O
Bigram O
Accuracy O
(%): O
0 O
Task2 O
methodology O
mark O
(out O
of O
25): O
13 O
Tutor Comment: Correct order for VOCAB and COUNTVEC: 1.Reading files with appropriate encoding 2.case normalisation 3.bigrams extraction using PMI assoc measure 4.stopword, rare tokens, length 3 (the order does not matter for these three) 5.stemming (not bigrams) 6.sparse file generation Correct order for ""100_UNI"" file: 1.case normalisation 2.CI stopword, length 3 (the order does not matter for these three) 3.stemming Correct order for ""100_BI"" file: 1.case normalisation 2.CI stopword, length 3, 3.bigrams calculation using ngrams() function. 4 Sorting using FreqDist or other	Sensemaking 1